{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\00_CODE\\03_Master_Thesis\\rdf-literal-preprocessing\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noctris\\.virtualenvs\\rdf-literal-preprocessing-20b3_M0v\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data dmg777k (66.17s).\n",
      "pruned (11.82s).\n"
     ]
    }
   ],
   "source": [
    "from dataload import dmg777k\n",
    "\n",
    "data = dmg777k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.binning import *\n",
    "import math\n",
    "def bin_numbers(data: Data, num_bins=3, use_lof=False, num_bins_as_percent=False, equal_height_binning=False, **kwargs):\n",
    "    relevent_relations = get_relevant_relations(\n",
    "        data, relevant_types=RDF_NUMBER_TYPES)\n",
    "    percent_of_objects = num_bins/100\n",
    "    \n",
    "    relation_bin_map = {}\n",
    "\n",
    "    for relation in relevent_relations:\n",
    "        if num_bins_as_percent:\n",
    "            sub_df = encode_number_sublist(\n",
    "            data.triples[data.triples[:, 1] == relation], data.i2e)\n",
    "            relation_bin_map[relation] = math.floor(len(sub_df[:,1].unique())*percent_of_objects)\n",
    "        else:\n",
    "            relation_bin_map[relation] = num_bins\n",
    "    max_bin = max([x for x in relation_bin_map.values()])\n",
    "    num_bins = max_bin\n",
    "    print(f'max_bin_number')\n",
    "\n",
    "\n",
    "    print(num_bins)\n",
    "    for b in range(num_bins):\n",
    "        o = (f'{URI_PREFIX}entity#binning{b+1}', f'{URI_PREFIX}datatype#bin')\n",
    "        new_id = len(data.i2e)\n",
    "        data.e2i[o] = new_id\n",
    "        data.i2e.append(o)\n",
    "        data.num_entities += 1\n",
    "\n",
    "    for r in relevent_relations:\n",
    "        p = f'{URI_PREFIX}predicat#binning{r}'\n",
    "        new_id = len(data.i2r)\n",
    "        data.r2i[p] = new_id\n",
    "        data.i2r.append(p)\n",
    "        data.num_relations += 1\n",
    "\n",
    "    for relation in relevent_relations:\n",
    "\n",
    "        sub_df = encode_number_sublist(\n",
    "            data.triples[data.triples[:, 1] == relation], data.i2e)\n",
    "\n",
    "        # TODO test new function\n",
    "        if (use_lof):\n",
    "            lof = LocalOutlierFactor(n_neighbors=10)\n",
    "            lof.fit(sub_df[:, 1].reshape(-1, 1))\n",
    "            outlier_scores = lof.negative_outlier_factor_\n",
    "            # Create a new column in the numpy array to store the outlier scores\n",
    "            # tensor_np = torch.hstack((encoded_df, outlier_scores.reshape(-1,1)))\n",
    "            threshold = np.percentile(outlier_scores, 10)\n",
    "            # use the outlier scores to filter out the outliers from the numpy array\n",
    "            sub_df = sub_df[outlier_scores > threshold]\n",
    "\n",
    "        if(num_bins_as_percent):\n",
    "            num_bins = math.floor(len(sub_df[:,1].unique())*percent_of_objects)\n",
    "            print(f'percentage based bins {percent_of_objects*100}% of unique literals results in {num_bins} bins')\n",
    "\n",
    "        # numpy is used here since torch.histc was not working for some reason.\n",
    "        sub_df = torch.cat(  # put bins and sub_df together\n",
    "            (sub_df, torch.from_numpy(  # get numpy solutions back\n",
    "                np.digitize(  # assign for each value in sub_df the corresponding bin\n",
    "                    sub_df[:, 1], np.histogram(  # calculate n bins based on values in sub_df\n",
    "                        sub_df[:, 1], num_bins)[1][:-1]\n",
    "                )\n",
    "            ).reshape(-1, 1)  # transfrom x tensor into (x,1) tensor to fit (x,2) shape of sub_df\n",
    "            ), 1)\n",
    "\n",
    "        object_mapping = np.vectorize(lambda t: data.e2i[(\n",
    "            f'{URI_PREFIX}entity#binning{t}', f'{URI_PREFIX}datatype#bin')])\n",
    "\n",
    "        predicat_mapping = np.vectorize(\n",
    "            lambda t: data.r2i[f'{URI_PREFIX}predicat#binning{relation}'])\n",
    "\n",
    "        sub_df[:, 1] = torch.tensor(np.array([predicat_mapping(sub_df[:, 2])]), dtype=torch.int32)\n",
    "        sub_df[:, 2] = torch.tensor(np.array([object_mapping(sub_df[:, 2])]), dtype=torch.int32)\n",
    "        data.triples = torch.cat((data.triples, sub_df), 0)\n",
    "    data = delete_empty_bin_types(data,max_bin)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_bin_number\n",
      "419\n",
      "percentage based bins 5.0% of unique literals results in 24 bins\n",
      "percentage based bins 5.0% of unique literals results in 419 bins\n",
      "percentage based bins 5.0% of unique literals results in 14 bins\n",
      "deleting relations [341723, 341727, 341728, 341729, 341730, 341731, 341732, 341733, 341734, 341735, 341736, 341737, 341738, 341739, 341740, 341741, 341742, 341743, 341744, 341745, 341746, 341747, 341748, 341749, 341750, 341751, 341752, 341753, 341754, 341755, 341756, 341757, 341758, 341759, 341760, 341761, 341762, 341763, 341764, 341765, 341766, 341767, 341768, 341769, 341770, 341771, 341772, 341773, 341774, 341775, 341776, 341777, 341778, 341779, 341780, 341781, 341782, 341783, 341784, 341785, 341786, 341787, 341788, 341789, 341790, 341791, 341792, 341793, 341794, 341795, 341796, 341797, 341798, 341799, 341800, 341801, 341802, 341803, 341804, 341805, 341806, 341807, 341808, 341809, 341810, 341811, 341812, 341813, 341814, 341815, 341816, 341817, 341818, 341819, 341820, 341821, 341822, 341823, 341824, 341825, 341826, 341827, 341828, 341829, 341830, 341831, 341832, 341833, 341834, 341835, 341836, 341837, 341838, 341839, 341840, 341841, 341842, 341843, 341844, 341845, 341846, 341847, 341848, 341849, 341850, 341851, 341852, 341853, 341854, 341855, 341856, 341857, 341858, 341859, 341860, 341861, 341862, 341863, 341864, 341865, 341866, 341867, 341868, 341869, 341870, 341871, 341872, 341873, 341874, 341875, 341876, 341877, 341878, 341879, 341880, 341881, 341882, 341883, 341884, 341885, 341886, 341887, 341888, 341889, 341890, 341891, 341892, 341893, 341894, 341895, 341896, 341897, 341898, 341899, 341900, 341901, 341902, 341903, 341904, 341905, 341906, 341907, 341908, 341909, 341910, 341911, 341912, 341913, 341914, 341915, 341916, 341917, 341918, 341919, 341920, 341921, 341922, 341923, 341924, 341925, 341926, 341927, 341928, 341929, 341930, 341931, 341932, 341933, 341934, 341935, 341936, 341937, 341938, 341939, 341940, 341941, 341942, 341943, 341944, 341945, 341947, 341950, 341954, 341956, 341957, 341960, 341961, 341962, 341963, 341964, 341966, 341970, 341974, 341976, 341977, 341980, 341982, 341983, 341984, 341985, 341986, 341987, 341988, 341989, 341995, 341997, 341998, 341999, 342003, 342004, 342010, 342013, 342015, 342016, 342017, 342018, 342020, 342024, 342025, 342026, 342027, 342028, 342029, 342030, 342031, 342032, 342033, 342034, 342035, 342036, 342037, 342038, 342039, 342040, 342041, 342042, 342046, 342049, 342050, 342052, 342054, 342056, 342060, 342061, 342063, 342064, 342073, 342074, 342084], since no occurences are given\n",
      "done deleteing\n",
      "unnamed_dataset\n"
     ]
    }
   ],
   "source": [
    "data = bin_numbers(data, 5,False, True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130685,     28,  54795],\n",
       "        [130685,     31, 201822],\n",
       "        [130690,     28,  58948],\n",
       "        ...,\n",
       "        [288824,     62, 341271],\n",
       "        [288858,     62, 341271],\n",
       "        [288866,     62, 341271]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://master-thesis.com/entity#binning419',\n",
       " 'http://master-thesis.com/datatype#bin')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.i2e[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf-literal-preprocessing-20b3_M0v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
