{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\00_CODE\\03_Master_Thesis\\rdf-literal-preprocessing\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "import sys\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kgbench as kg\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as pl\n",
    "import random as rd\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils import RDF_NUMBER_TYPES, get_relevant_relations, add_triple, get_p_types, ALL_LITERALS\n",
    "from kgbench.load import Data\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from utils import URI_PREFIX\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload import dmg777k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data dmg777k (55.27s).\n",
      "pruned (9.95s).\n"
     ]
    }
   ],
   "source": [
    "data = dmg777k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "for rr in relrel\n"
     ]
    }
   ],
   "source": [
    "relevent_relations = get_relevant_relations(data, relevant_types=RDF_NUMBER_TYPES)\n",
    "num_bins=3\n",
    "print(len(relevent_relations))\n",
    "verbose = 1\n",
    "i = 0\n",
    "cumsum = 0\n",
    "bins = np.arange(num_bins)\n",
    "print(\"for rr in relrel\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "created new entity:\n",
      "341271 - ('http://master-thesis.com/entity#binning1', 'http://master-thesis.com/datatype#bin')\n",
      "created new entity:\n",
      "341272 - ('http://master-thesis.com/entity#binning2', 'http://master-thesis.com/datatype#bin')\n",
      "created new entity:\n",
      "341273 - ('http://master-thesis.com/entity#binning3', 'http://master-thesis.com/datatype#bin')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(num_bins)\n",
    "for b in range(num_bins):\n",
    "    o = (f'{URI_PREFIX}entity#binning{b+1}',f'{URI_PREFIX}datatype#bin')\n",
    "    new_id = len(data.i2e)\n",
    "    data.e2i[o] = new_id\n",
    "    data.i2e.append(o)\n",
    "    data.num_entities += 1\n",
    "    if (verbose > 0):\n",
    "        print(f'created new entity:')\n",
    "        print(f'{data.e2i[o]} - {o}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 2, 43]\n",
      "created new relation:\n",
      "60 - http://master-thesis.com/predicat#binning26\n",
      "created new relation:\n",
      "61 - http://master-thesis.com/predicat#binning2\n",
      "created new relation:\n",
      "62 - http://master-thesis.com/predicat#binning43\n"
     ]
    }
   ],
   "source": [
    "print(relevent_relations)\n",
    "for r in relevent_relations:\n",
    "    p = f'{URI_PREFIX}predicat#binning{r}'\n",
    "    new_id = len(data.i2r)\n",
    "    data.r2i[p] = new_id\n",
    "    data.i2r.append(p)\n",
    "    data.num_relations += 1\n",
    "    if (verbose > 0):\n",
    "        print(f'created new relation:')\n",
    "        print(f'{data.r2i[p]} - {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_number_sublist(df: torch.Tensor, i2e: List[str]) -> torch.Tensor:\n",
    "    sub_df = df.clone()\n",
    "    for i in range(len(sub_df)):\n",
    "        sub_df[i, 1] = torch.tensor(\n",
    "            float(i2e[sub_df[i, 2]][0]), dtype=torch.float32)\n",
    "    sub_df = sub_df[:, :2]\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777124\n"
     ]
    }
   ],
   "source": [
    "print(len(data.triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "00:00:00\n",
      "sub2\n",
      "510\n",
      "aaa\n",
      "2\n",
      "00:00:00\n",
      "sub2\n",
      "8396\n",
      "aaa\n",
      "43\n",
      "00:00:00\n",
      "sub2\n",
      "1800\n",
      "aaa\n"
     ]
    }
   ],
   "source": [
    "for rr in relevent_relations:\n",
    "    print(rr)\n",
    "    print(datetime.time())\n",
    "    df = data.triples.clone()\n",
    "    df = df[df[:, 1]== rr]\n",
    "    sub_df = encode_number_sublist(df, data.i2e)\n",
    "    print(\"sub2\")\n",
    "    sub_df = torch.cat( #put bins and sub_df together\n",
    "        (sub_df, torch.from_numpy( #get numpy solutions back\n",
    "            np.digitize( # assign for each value in sub_df the corresponding bin\n",
    "                sub_df[:, 1], np.histogram( # calculate n bins based on values in sub_df\n",
    "                    sub_df[:, 1], num_bins)[1][:-1]\n",
    "                )\n",
    "            ).reshape(-1, 1) # transfrom x tensor into (x,1) tensor to fit (x,2) shape of sub_df\n",
    "        ), 1)\n",
    "    \n",
    "    ofn = lambda t: data.e2i[(f'{URI_PREFIX}entity#binning{t}',f'{URI_PREFIX}datatype#bin')]\n",
    "    vofn = np.vectorize(ofn)\n",
    "    pfn = lambda t: data.r2i[f'{URI_PREFIX}predicat#binning{rr}']\n",
    "    vpfn = np.vectorize(pfn)\n",
    "    to_add_df = sub_df.clone()\n",
    "    print(len(to_add_df))\n",
    "    #print(sub_df[:,2])\n",
    "    print(\"aaa\")\n",
    "    to_add_df[:,1]= torch.tensor([vpfn(sub_df[:,2])], dtype=torch.int32)\n",
    "    to_add_df[:,2]= torch.tensor([vofn(sub_df[:,2])],dtype=torch.int32)\n",
    "    #print(to_add_df)\n",
    "    #print(np.unique(vofn(sub_df[:,2])))\n",
    "    #print(np.unique(vpfn(sub_df[:,2])))\n",
    "    #print(vpfn(sub_df[:,2]))\n",
    "    #print('eee')\n",
    "    #print(num_bins)\n",
    "    #print(torch.unique(sub_df[:,2]))\n",
    "    #print(\"suib\")\n",
    "    data.triples = torch.cat((data.triples, to_add_df), 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787830\n"
     ]
    }
   ],
   "source": [
    "print(len(data.triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.50000e+01, 2.47242e+05, 4.94439e+05])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram( # calculate n bins based on values in sub_df\n",
    "                    sub_df[:, 1], num_bins)[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize( # assign for each value in sub_df the corresponding bin\n",
    "                sub_df[:, 1], np.histogram( # calculate n bins based on values in sub_df\n",
    "                    sub_df[:, 1], num_bins)[1][:-1]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mport numpy as np\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "squarer = lambda t: t ** 2\n",
    "vfunc = np.vectorize(squarer)\n",
    "vfunc(x)\n",
    "# Output : array([ 1,  4,  9, 16, 25])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf-literal-preprocessing-20b3_M0v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
