{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\00_CODE\\03_Master_Thesis\\rdf-literal-preprocessing\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noctris\\.virtualenvs\\rdf-literal-preprocessing-20b3_M0v\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fire\n",
    "import sys\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kgbench as kg\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as pl\n",
    "import random as rd\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils import RDF_NUMBER_TYPES, get_relevant_relations, add_triple, get_p_types, ALL_LITERALS\n",
    "from kgbench.load import Data\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from utils import URI_PREFIX\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import datetime\n",
    "from typing import List, Sequence, Tuple\n",
    "from utils import URI_PREFIX\n",
    "from preprocess.binning import delete_empty_bin_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data dmg777k (55.89s).\n",
      "pruned (9.622s).\n"
     ]
    }
   ],
   "source": [
    "from dataload import dmg777k\n",
    "data = dmg777k()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterating bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 3\n",
    "relevent_relations = get_relevant_relations(\n",
    "    data, relevant_types=RDF_NUMBER_TYPES)\n",
    "\n",
    "for b in range(num_bins):\n",
    "    o = (f'{URI_PREFIX}entity#binning{b+1}#1', f'{URI_PREFIX}datatype#bin')\n",
    "    new_id = len(data.i2e)\n",
    "    data.e2i[o] = new_id\n",
    "    data.i2e.append(o)\n",
    "    data.num_entities += 1\n",
    "\n",
    "    o = (f'{URI_PREFIX}entity#binning{b}#2', f'{URI_PREFIX}datatype#bin')\n",
    "    new_id = len(data.i2e)\n",
    "    data.e2i[o] = new_id\n",
    "    data.i2e.append(o)\n",
    "    data.num_entities += 1\n",
    "\n",
    "for r in relevent_relations:\n",
    "    p = f'{URI_PREFIX}predicat#binning{r}#1'\n",
    "    new_id = len(data.i2r)\n",
    "    data.r2i[p] = new_id\n",
    "    data.i2r.append(p)\n",
    "    data.num_relations += 1\n",
    "    p = f'{URI_PREFIX}predicat#binning{r}#2'\n",
    "    new_id = len(data.i2r)\n",
    "    data.r2i[p] = new_id\n",
    "    data.i2r.append(p)\n",
    "    data.num_relations += 1\n",
    "\n",
    "for relation in relevent_relations:\n",
    "\n",
    "    sub_df1 = encode_number_sublist(\n",
    "        data.triples[data.triples[:, 1] == relation], data.i2e)\n",
    "    sub_df2 = encode_number_sublist(\n",
    "        data.triples[data.triples[:, 1] == relation], data.i2e)\n",
    "\n",
    "    # numpy is used here since torch.histc was not working for some reason.\n",
    "    sub_df1 = torch.cat(  # put bins and sub_df together\n",
    "        (sub_df1, torch.from_numpy(  # get numpy solutions back\n",
    "            np.digitize(  # assign for each value in sub_df the corresponding bin\n",
    "                sub_df1[:, 1], np.histogram(  # calculate n bins based on values in sub_df\n",
    "                    sub_df1[:, 1], num_bins*2)[1][:-1:2]\n",
    "            )\n",
    "        ).reshape(-1, 1)  # transfrom x tensor into (x,1) tensor to fit (x,2) shape of sub_df\n",
    "        ), 1)\n",
    "    sub_df2 = torch.cat(  # put bins and sub_df together\n",
    "        (sub_df2, torch.from_numpy(  # get numpy solutions back\n",
    "            np.digitize(  # assign for each value in sub_df the corresponding bin\n",
    "                sub_df2[:, 1], np.histogram(  # calculate n bins based on values in sub_df\n",
    "                    sub_df2[:, 1], num_bins*2)[1][1::2]\n",
    "            )\n",
    "        ).reshape(-1, 1)  # transfrom x tensor into (x,1) tensor to fit (x,2) shape of sub_df\n",
    "        ), 1)\n",
    "\n",
    "    object_mapping1 = np.vectorize(lambda t: data.e2i[(\n",
    "        f'{URI_PREFIX}entity#binning{t}#1', f'{URI_PREFIX}datatype#bin')])\n",
    "\n",
    "    predicat_mapping1 = np.vectorize(\n",
    "        lambda t: data.r2i[f'{URI_PREFIX}predicat#binning{relation}#1'])\n",
    "\n",
    "    sub_df1[:, 1] = torch.tensor([predicat_mapping1(sub_df1[:, 2])], dtype=torch.int32)\n",
    "    sub_df1[:, 2] = torch.tensor([object_mapping1(sub_df1[:, 2])], dtype=torch.int32)\n",
    "    data.triples = torch.cat((data.triples, sub_df1), 0)\n",
    "\n",
    "    object_mapping2 = np.vectorize(lambda t: data.e2i[(\n",
    "        f'{URI_PREFIX}entity#binning{t}#2', f'{URI_PREFIX}datatype#bin')])\n",
    "    object_mapping22 = np.vectorize(lambda t: num_bins-1 if t>=num_bins else t)\n",
    "\n",
    "    predicat_mapping2 = np.vectorize(\n",
    "        lambda t: data.r2i[f'{URI_PREFIX}predicat#binning{relation}#2'])\n",
    "\n",
    "    sub_df2[:, 1] = torch.tensor([predicat_mapping2(sub_df2[:, 2])], dtype=torch.int32)\n",
    "    sub_df2[:, 2] = torch.tensor([object_mapping22(sub_df2[:, 2])], dtype=torch.int32)\n",
    "    sub_df2[:, 2] = torch.tensor([object_mapping2(sub_df2[:, 2])], dtype=torch.int32)\n",
    "    data.triples = torch.cat((data.triples, sub_df2), 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subpopulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j: 0 - prop: 0.7784313725490196 - kl_div: 100.03431\n",
      "j: 1 - prop: 0.6215686274509804 - kl_div: 153.5318\n",
      "j: 2 - prop: 1.0 - kl_div: 0.0\n",
      "j: 3 - prop: 1.0 - kl_div: 0.0\n",
      "j: 4 - prop: 1.0 - kl_div: 0.0\n",
      "j: 5 - prop: 1.0 - kl_div: 0.0\n",
      "j: 6 - prop: 1.0 - kl_div: 0.0\n",
      "j: 7 - prop: 1.0 - kl_div: 0.0\n",
      "j: 8 - prop: 1.0 - kl_div: 0.0\n",
      "j: 9 - prop: 1.0 - kl_div: 0.0\n",
      "j: 10 - prop: 1.0 - kl_div: 0.0\n",
      "j: 11 - prop: 1.0 - kl_div: 0.0\n",
      "j: 12 - prop: 1.0 - kl_div: 0.0\n",
      "j: 13 - prop: 1.0 - kl_div: 0.0\n",
      "j: 14 - prop: 1.0 - kl_div: 0.0\n",
      "j: 15 - prop: 0.7764705882352941 - kl_div: 100.63174\n",
      "j: 16 - prop: 0.06274509803921569 - kl_div: 92.89656\n",
      "j: 17 - prop: 0.00392156862745098 - kl_div: 14.92516\n",
      "j: 0 - prop: 1.0 - kl_div: 0.0\n",
      "j: 1 - prop: 1.0 - kl_div: 0.0\n",
      "j: 2 - prop: 1.0 - kl_div: 0.0\n",
      "j: 3 - prop: 1.0 - kl_div: 0.0\n",
      "j: 4 - prop: 1.0 - kl_div: 0.0\n",
      "j: 5 - prop: 1.0 - kl_div: 0.0\n",
      "j: 6 - prop: 1.0 - kl_div: 0.0\n",
      "j: 7 - prop: 1.0 - kl_div: 0.0\n",
      "j: 8 - prop: 1.0 - kl_div: 0.0\n",
      "j: 9 - prop: 1.0 - kl_div: 0.0\n",
      "j: 10 - prop: 1.0 - kl_div: 0.0\n",
      "j: 11 - prop: 0.17317770366841354 - kl_div: 3743.86096\n",
      "j: 12 - prop: 0.0 - kl_div: 0.0\n",
      "j: 13 - prop: 0.11434016198189614 - kl_div: 1942.76852\n",
      "j: 14 - prop: 0.0 - kl_div: 0.0\n",
      "j: 15 - prop: 0.0 - kl_div: 0.0\n",
      "j: 16 - prop: 0.011314911862791805 - kl_div: 462.51359\n",
      "j: 17 - prop: 0.011314911862791805 - kl_div: 462.51359\n",
      "j: 18 - prop: 0.012505955216769891 - kl_div: 436.96134\n",
      "j: 19 - prop: 0.003692234397332063 - kl_div: 176.26342\n",
      "j: 20 - prop: 0.013696998570747975 - kl_div: 761.2047\n",
      "j: 21 - prop: 0.01095759885659838 - kl_div: 412.08495\n",
      "2 has 3 subpopulations\n",
      "len subpopulation 1454\n",
      "len subpopulation 960\n",
      "len subpopulation 5982\n",
      "j: 0 - prop: 1.0 - kl_div: 0.0\n",
      "j: 1 - prop: 1.0 - kl_div: 0.0\n",
      "j: 2 - prop: 1.0 - kl_div: 0.0\n",
      "j: 3 - prop: 1.0 - kl_div: 0.0\n",
      "j: 4 - prop: 1.0 - kl_div: 0.0\n",
      "j: 5 - prop: 1.0 - kl_div: 0.0\n",
      "j: 6 - prop: 1.0 - kl_div: 0.0\n",
      "j: 7 - prop: 1.0 - kl_div: 0.0\n",
      "j: 8 - prop: 1.0 - kl_div: 0.0\n",
      "j: 9 - prop: 1.0 - kl_div: 0.0\n",
      "j: 10 - prop: 1.0 - kl_div: 0.0\n",
      "j: 11 - prop: 1.0 - kl_div: 0.0\n",
      "j: 12 - prop: 1.0 - kl_div: 0.0\n",
      "j: 13 - prop: 1.0 - kl_div: 0.0\n",
      "j: 14 - prop: 0.4127777777777778 - kl_div: 4735.74484\n",
      "j: 15 - prop: 0.0 - kl_div: 0.0\n",
      "j: 16 - prop: 0.24944444444444444 - kl_div: 390.89206\n",
      "j: 17 - prop: 0.08666666666666667 - kl_div: 286.30268\n",
      "j: 18 - prop: 0.08666666666666667 - kl_div: 286.30268\n",
      "j: 19 - prop: 0.020555555555555556 - kl_div: 128.43833\n",
      "j: 20 - prop: 0.021111111111111112 - kl_div: 135.27273\n",
      "j: 21 - prop: 0.012777777777777779 - kl_div: 131.69551\n",
      "j: 22 - prop: 0.005555555555555556 - kl_div: 148.96357\n",
      "43 has 3 subpopulations\n",
      "len subpopulation 743\n",
      "len subpopulation 449\n",
      "len subpopulation 608\n"
     ]
    }
   ],
   "source": [
    "from preprocess import subpopulation_binning\n",
    "data = subpopulation_binning(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'triples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[39m.\u001b[39;49mtriples\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'triples'"
     ]
    }
   ],
   "source": [
    "data.triples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf-literal-preprocessing-20b3_M0v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
