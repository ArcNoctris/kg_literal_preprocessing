{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\00_CODE\\03_Master_Thesis\\rdf-literal-preprocessing\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data amplus (63.39s).\n",
      "pruned (37.34s).\n"
     ]
    }
   ],
   "source": [
    "from dataload import amplus\n",
    "\n",
    "data = amplus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POTENTIAL_TEXT_TYPES = [\n",
    "    '@es', '@fy', '@nl', '@nl-nl', '@pt', '@ru',\n",
    "    'http://www.w3.org/1999/02/22-rdf-syntax-ns#langString',\n",
    "    'http://www.w3.org/2001/XMLSchema#string',\n",
    "    'none'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_relevant_relations\n",
    "import re\n",
    "rr = get_relevant_relations(data,['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iri',\n",
       " 'blank_node',\n",
       " 'none',\n",
       " 'http://kgbench.info/dt#base64Image',\n",
       " 'http://www.w3.org/2001/XMLSchema#date',\n",
       " 'http://www.w3.org/2001/XMLSchema#decimal',\n",
       " 'http://www.w3.org/2001/XMLSchema#positiveInteger']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.datatypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', 'none')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.i2e[507071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[122633,     10, 507071],\n",
       "        [122638,     10, 507071],\n",
       "        [122641,     10, 507071],\n",
       "        ...,\n",
       "        [506770,     10, 508173],\n",
       "        [506771,     10, 507071],\n",
       "        [506773,     10, 507071]], dtype=torch.int32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.triples[data.triples[:,1]==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 10, 11, 16, 17, 18, 0, 2, 7, 20, 4, 5, 25]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "import torch\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "#languages = ['dutch','spain','french','portuguese']\n",
    "#stopword_list = stopwords.words('dutch')\n",
    "\n",
    "def get_stopword_list(languages = ['dutch','spanish','french','portuguese','english']):\n",
    "    stopword_list= []\n",
    "    for language in languages:\n",
    "        stopword_list.extend(stopwords.words(language))\n",
    "    return stopword_list\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(word_array, stopword_list):\n",
    "    return [word for word in word_array\n",
    "             if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'en',\n",
       " 'van',\n",
       " 'ik',\n",
       " 'te',\n",
       " 'dat',\n",
       " 'die',\n",
       " 'in',\n",
       " 'een',\n",
       " 'hij',\n",
       " 'het',\n",
       " 'niet',\n",
       " 'zijn',\n",
       " 'is',\n",
       " 'was',\n",
       " 'op',\n",
       " 'aan',\n",
       " 'met',\n",
       " 'als',\n",
       " 'voor',\n",
       " 'had',\n",
       " 'er',\n",
       " 'maar',\n",
       " 'om',\n",
       " 'hem',\n",
       " 'dan',\n",
       " 'zou',\n",
       " 'of',\n",
       " 'wat',\n",
       " 'mijn',\n",
       " 'men',\n",
       " 'dit',\n",
       " 'zo',\n",
       " 'door',\n",
       " 'over',\n",
       " 'ze',\n",
       " 'zich',\n",
       " 'bij',\n",
       " 'ook',\n",
       " 'tot',\n",
       " 'je',\n",
       " 'mij',\n",
       " 'uit',\n",
       " 'der',\n",
       " 'daar',\n",
       " 'haar',\n",
       " 'naar',\n",
       " 'heb',\n",
       " 'hoe',\n",
       " 'heeft',\n",
       " 'hebben',\n",
       " 'deze',\n",
       " 'u',\n",
       " 'want',\n",
       " 'nog',\n",
       " 'zal',\n",
       " 'me',\n",
       " 'zij',\n",
       " 'nu',\n",
       " 'ge',\n",
       " 'geen',\n",
       " 'omdat',\n",
       " 'iets',\n",
       " 'worden',\n",
       " 'toch',\n",
       " 'al',\n",
       " 'waren',\n",
       " 'veel',\n",
       " 'meer',\n",
       " 'doen',\n",
       " 'toen',\n",
       " 'moet',\n",
       " 'ben',\n",
       " 'zonder',\n",
       " 'kan',\n",
       " 'hun',\n",
       " 'dus',\n",
       " 'alles',\n",
       " 'onder',\n",
       " 'ja',\n",
       " 'eens',\n",
       " 'hier',\n",
       " 'wie',\n",
       " 'werd',\n",
       " 'altijd',\n",
       " 'doch',\n",
       " 'wordt',\n",
       " 'wezen',\n",
       " 'kunnen',\n",
       " 'ons',\n",
       " 'zelf',\n",
       " 'tegen',\n",
       " 'na',\n",
       " 'reeds',\n",
       " 'wil',\n",
       " 'kon',\n",
       " 'niets',\n",
       " 'uw',\n",
       " 'iemand',\n",
       " 'geweest',\n",
       " 'andere',\n",
       " 'de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened',\n",
       " 'au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent',\n",
       " 'a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'às',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'é',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'éramos',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estão',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'estávamos',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estivéramos',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'fôramos',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'fôssemos',\n",
       " 'fui',\n",
       " 'há',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'hão',\n",
       " 'havemos',\n",
       " 'haver',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houverá',\n",
       " 'houveram',\n",
       " 'houvéramos',\n",
       " 'houverão',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houveríamos',\n",
       " 'houvermos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvéssemos',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'não',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nós',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'são',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'ser',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'só',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'também',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'tém',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 'tínhamos',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tivéramos',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stopword_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import URI_PREFIX\n",
    "from preprocess.binning import delete_empty_bin_types\n",
    "def LDA_topic_assignment(data, num_topics=10, min_mean_word_count = 3, max_assigned_topic = 3, min_topic_relevance = 0.1 ):   \n",
    "    relevent_relations = get_relevant_relations(\n",
    "        data, relevant_types=POTENTIAL_TEXT_TYPES)\n",
    "    #print(num_bins)\n",
    "    for b in range(num_topics):\n",
    "        o = (f'{URI_PREFIX}entity#topic{b}', f'{URI_PREFIX}datatype#topics')\n",
    "        new_id = len(data.i2e)\n",
    "        data.e2i[o] = new_id\n",
    "        data.i2e.append(o)\n",
    "        data.num_entities += 1\n",
    "\n",
    "    stopword_list = get_stopword_list()\n",
    "    for r in relevent_relations:\n",
    "        df = pd.DataFrame(data.triples[data.triples[:,1]== r], columns=['s','p','o'])\n",
    "        df['text'] = df['o'].apply(lambda t: data.i2e[t][0])\n",
    "        df['type'] = df['o'].apply(lambda t: data.i2e[t][1])\n",
    "    \n",
    "        # delete \"none type\" polygons \n",
    "        df['text'] = df['text'].apply(lambda t:'' if re.match('(MULTIPOLYGON|POLYGON)',t) else t)\n",
    "        mean_num_words = df['text'].str.count(r'([\\w\\:\\.\\/]{3,})').mean()\n",
    "        #print(mean_num_words)\n",
    "        if mean_num_words > min_mean_word_count:\n",
    "            p = f'{URI_PREFIX}predicat#topics{r}'\n",
    "            new_id = len(data.i2r)\n",
    "            data.r2i[p] = new_id\n",
    "            data.i2r.append(p)\n",
    "            data.num_relations += 1\n",
    "\n",
    "\n",
    "\n",
    "            df['text_preprocessed'] = df['text'].apply(lambda t: gensim.utils.simple_preprocess(t, deacc=True))\n",
    "            df['text_preprocessed'] = df['text_preprocessed'].apply(lambda t: remove_stopwords(t, stopword_list=stopword_list))\n",
    "\n",
    "            data_words = df.text_preprocessed.values.tolist()\n",
    "            #data_words = list(sent_to_words(text_data))\n",
    "            print(data_words[:1][0][:30])\n",
    "            # Create Dictionary\n",
    "            id2word = corpora.Dictionary(data_words)\n",
    "            # Term Document Frequency\n",
    "            corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "            print(corpus[:1][0][:30])\n",
    "            num_topics = 10\n",
    "            lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "            df['vector'] = df['text_preprocessed'].apply(lambda t: id2word.doc2bow(t))\n",
    "            df['topics'] = df['vector'].apply(lambda t: [x[0] for x in sorted(lda_model.get_document_topics(t), key=lambda x: x[1], reverse=True)[:3] if x[1]>0.1])\n",
    "            for i in range(num_topics):\n",
    "                df[f'topic_{i}'] = df['topics'].apply(lambda t: True if i in t else False)\n",
    "        \n",
    "            for i in range(num_topics):\n",
    "\n",
    "                sub = df[df[f'topic_{i}']==True]\n",
    "                if  len(sub)> 0:\n",
    "                    sub_df = torch.zeros(len(sub),3,dtype=torch.int32)\n",
    "                    sub_df[:,0] = torch.tensor(sub.s.tolist(), dtype=torch.int32)\n",
    "                    #torch.full((len(sub),1),data.r2i[f'{URI_PREFIX}predicat#topics{9}'], dtype=torch.int32)\n",
    "                    sub_df[:,1] = data.r2i[f'{URI_PREFIX}predicat#topics{r}']\n",
    "                    sub_df[:,2] = data.e2i[f'{URI_PREFIX}entity#topic{i}', f'{URI_PREFIX}datatype#topics']\n",
    "                    data.triples = torch.cat((data.triples, sub_df), 0)\n",
    "    data = delete_empty_bin_types(data,num_topics)\n",
    "    return data\n",
    "\n",
    "        #break \n",
    "\n",
    "    # remove stop words\n",
    "    #data_words = remove_stopwords(data_words)\n",
    "\n",
    "    #print(data_words[:1][0][:30])\n",
    "\n",
    "\n",
    "    # # Create Dictionary\n",
    "\n",
    "\n",
    "    # # Create Corpus\n",
    "    # texts = data_words\n",
    "\n",
    "    # # Term Document Frequency\n",
    "    # corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # # View\n",
    "    # print(corpus[:1][0][:30])\n",
    "    # # number of topics\n",
    "    # num_topics = 10\n",
    "\n",
    "    # # Build LDA model\n",
    "    # lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "    #                                    id2word=id2word,\n",
    "    #                                    num_topics=num_topics)\n",
    "\n",
    "    # # Print the Keyword in the 10 topics\n",
    "    # print(lda_model.print_topics())\n",
    "    # doc_lda = lda_model[corpus]\n",
    "    # models[r] = (lda_model,corpus)\n",
    "\n",
    "#     # LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "#         t = dfs[9]['text_processed'].iloc[23]\n",
    "# id2word.doc2bow(remove_stopwords(list(sent_to_words([t])))[0])\n",
    "# [x[0] for x in sorted(lda_model.get_document_topics(id2word.doc2bow(remove_stopwords(list(sent_to_words([t])))[0])), key=lambda x: x[1], reverse=True)[:3] if x[1]>0.1]\n",
    "#         break\n",
    "#         print(r)\n",
    "#         print(mean_num_words)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = torch.zeros(len(sub),3,dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[:,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61],\n",
       "        [61]], dtype=torch.int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((len(sub),1),data.r2i[f'{URI_PREFIX}predicat#topics{9}'], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rijk', 'gekleed']\n",
      "[(0, 1), (1, 1)]\n",
      "['geboren', 'luik', 'overleden', 'amsterdam', 'verbleef', 'jeugd', 'korte', 'tijd', 'rome', 'luik', 'opgeleid', 'bertholet', 'flemalle', 'vestigde', 'voorgoed', 'amsterdam', 'vroegste', 'werk', 'overdadig', 'barok', 'later', 'belargrijkste', 'hollandse', 'classicisme', 'trant', 'schilderde', 'plafonds', 'meestal', 'allegorische', 'mythologische']\n",
      "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n",
      "['stadhuis', 'dam', 'amsterdam', 'pieter', 'saenredam']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "data = LDA_topic_assignment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://master-thesis.com/entity#topic7',\n",
       " 'http://master-thesis.com/datatype#topics')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.i2e[341277]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130685,     28,  54795],\n",
       "        [130685,     31, 201822],\n",
       "        [130690,     28,  58948],\n",
       "        ...,\n",
       "        [271522,     61, 341275],\n",
       "        [271523,     61, 341275],\n",
       "        [271535,     61, 341277]], dtype=torch.int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_numbers(data: Data, num_bins=3, use_lof=False, num_bins_as_percent=False, equal_height_binning=False, **kwargs):\n",
    "    relevent_relations = get_relevant_relations(\n",
    "        data, relevant_types=RDF_NUMBER_TYPES)\n",
    "    print(num_bins)\n",
    "    for b in range(num_bins):\n",
    "        o = (f'{URI_PREFIX}entity#binning{b+1}', f'{URI_PREFIX}datatype#bin')\n",
    "        new_id = len(data.i2e)\n",
    "        data.e2i[o] = new_id\n",
    "        data.i2e.append(o)\n",
    "        data.num_entities += 1\n",
    "\n",
    "    for r in relevent_relations:\n",
    "        p = f'{URI_PREFIX}predicat#binning{r}'\n",
    "        new_id = len(data.i2r)\n",
    "        data.r2i[p] = new_id\n",
    "        data.i2r.append(p)\n",
    "        data.num_relations += 1\n",
    "\n",
    "    for relation in relevent_relations:\n",
    "\n",
    "        sub_df = encode_number_sublist(\n",
    "            data.triples[data.triples[:, 1] == relation], data.i2e)\n",
    "\n",
    "        # TODO test new function\n",
    "        if (use_lof):\n",
    "            lof = LocalOutlierFactor(n_neighbors=10)\n",
    "            lof.fit(sub_df[:, 1].reshape(-1, 1))\n",
    "            outlier_scores = lof.negative_outlier_factor_\n",
    "            # Create a new column in the numpy array to store the outlier scores\n",
    "            # tensor_np = torch.hstack((encoded_df, outlier_scores.reshape(-1,1)))\n",
    "            threshold = np.percentile(outlier_scores, 10)\n",
    "            # use the outlier scores to filter out the outliers from the numpy array\n",
    "            sub_df = sub_df[outlier_scores > threshold]\n",
    "\n",
    "        # numpy is used here since torch.histc was not working for some reason.\n",
    "        sub_df = torch.cat(  # put bins and sub_df together\n",
    "            (sub_df, torch.from_numpy(  # get numpy solutions back\n",
    "                np.digitize(  # assign for each value in sub_df the corresponding bin\n",
    "                    sub_df[:, 1], np.histogram(  # calculate n bins based on values in sub_df\n",
    "                        sub_df[:, 1], num_bins)[1][:-1]\n",
    "                )\n",
    "            ).reshape(-1, 1)  # transfrom x tensor into (x,1) tensor to fit (x,2) shape of sub_df\n",
    "            ), 1)\n",
    "\n",
    "        object_mapping = np.vectorize(lambda t: data.e2i[(\n",
    "            f'{URI_PREFIX}entity#binning{t}', f'{URI_PREFIX}datatype#bin')])\n",
    "\n",
    "        predicat_mapping = np.vectorize(\n",
    "            lambda t: data.r2i[f'{URI_PREFIX}predicat#binning{relation}'])\n",
    "\n",
    "        sub_df[:, 1] = torch.tensor(np.array([predicat_mapping(sub_df[:, 2])]), dtype=torch.int32)\n",
    "        sub_df[:, 2] = torch.tensor(np.array([object_mapping(sub_df[:, 2])]), dtype=torch.int32)\n",
    "        data.triples = torch.cat((data.triples, sub_df), 0)\n",
    "    data = delete_empty_bin_types(data,num_bins)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([9, 57, 53, 39])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>vector</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211086</td>\n",
       "      <td>9</td>\n",
       "      <td>28734</td>\n",
       "      <td>Exterieur, overzicht Administratiegebouw, voor...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[exterieur, overzicht, voorgevel, kleine, gebo...</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211090</td>\n",
       "      <td>9</td>\n",
       "      <td>27816</td>\n",
       "      <td>Exterieur overzicht</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[exterieur, overzicht]</td>\n",
       "      <td>[(1, 1), (6, 1)]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211091</td>\n",
       "      <td>9</td>\n",
       "      <td>27816</td>\n",
       "      <td>Exterieur overzicht</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[exterieur, overzicht]</td>\n",
       "      <td>[(1, 1), (6, 1)]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211092</td>\n",
       "      <td>9</td>\n",
       "      <td>27816</td>\n",
       "      <td>Exterieur overzicht</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[exterieur, overzicht]</td>\n",
       "      <td>[(1, 1), (6, 1)]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211093</td>\n",
       "      <td>9</td>\n",
       "      <td>27816</td>\n",
       "      <td>Exterieur overzicht</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[exterieur, overzicht]</td>\n",
       "      <td>[(1, 1), (6, 1)]</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57037</th>\n",
       "      <td>288864</td>\n",
       "      <td>9</td>\n",
       "      <td>20416</td>\n",
       "      <td>BOERDERIJ. Vrijstaand woonhuis onder pannen sc...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[boerderij, vrijstaand, woonhuis, pannen, schi...</td>\n",
       "      <td>[(68, 1), (141, 1), (175, 2), (192, 1), (236, ...</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57038</th>\n",
       "      <td>288866</td>\n",
       "      <td>9</td>\n",
       "      <td>42149</td>\n",
       "      <td>Ned.Herv.Kerk. Bouwwerk, bestaande uit het vee...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[ned, herv, kerk, bouwwerk, bestaande, veelhoe...</td>\n",
       "      <td>[(24, 1), (54, 2), (85, 1), (175, 1), (221, 1)...</td>\n",
       "      <td>[1, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57039</th>\n",
       "      <td>288868</td>\n",
       "      <td>9</td>\n",
       "      <td>38668</td>\n",
       "      <td>Korenmolen \"De Koutermolen\". Ronde stenen bove...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[korenmolen, koutermolen, ronde, stenen, boven...</td>\n",
       "      <td>[(73, 1), (165, 1), (234, 1), (506, 1), (768, ...</td>\n",
       "      <td>[0, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57040</th>\n",
       "      <td>288870</td>\n",
       "      <td>9</td>\n",
       "      <td>80531</td>\n",
       "      <td>Woonhuis in gele baksteen met rode bakstenen l...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[woonhuis, gele, baksteen, rode, bakstenen, la...</td>\n",
       "      <td>[(5, 1), (42, 2), (175, 1), (192, 1), (236, 1)...</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57041</th>\n",
       "      <td>288872</td>\n",
       "      <td>9</td>\n",
       "      <td>73296</td>\n",
       "      <td>R.K.Kerk van de H.Bonifacius. Eenbeukige neogo...</td>\n",
       "      <td>@nl-nl</td>\n",
       "      <td>[kerk, bonifacius, eenbeukige, neogotische, kr...</td>\n",
       "      <td>[(15, 1), (42, 1), (54, 1), (85, 1), (175, 1),...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57042 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            s  p      o                                               text  \\\n",
       "0      211086  9  28734  Exterieur, overzicht Administratiegebouw, voor...   \n",
       "1      211090  9  27816                                Exterieur overzicht   \n",
       "2      211091  9  27816                                Exterieur overzicht   \n",
       "3      211092  9  27816                                Exterieur overzicht   \n",
       "4      211093  9  27816                                Exterieur overzicht   \n",
       "...       ... ..    ...                                                ...   \n",
       "57037  288864  9  20416  BOERDERIJ. Vrijstaand woonhuis onder pannen sc...   \n",
       "57038  288866  9  42149  Ned.Herv.Kerk. Bouwwerk, bestaande uit het vee...   \n",
       "57039  288868  9  38668  Korenmolen \"De Koutermolen\". Ronde stenen bove...   \n",
       "57040  288870  9  80531  Woonhuis in gele baksteen met rode bakstenen l...   \n",
       "57041  288872  9  73296  R.K.Kerk van de H.Bonifacius. Eenbeukige neogo...   \n",
       "\n",
       "         type                                  text_preprocessed  \\\n",
       "0      @nl-nl  [exterieur, overzicht, voorgevel, kleine, gebo...   \n",
       "1      @nl-nl                             [exterieur, overzicht]   \n",
       "2      @nl-nl                             [exterieur, overzicht]   \n",
       "3      @nl-nl                             [exterieur, overzicht]   \n",
       "4      @nl-nl                             [exterieur, overzicht]   \n",
       "...       ...                                                ...   \n",
       "57037  @nl-nl  [boerderij, vrijstaand, woonhuis, pannen, schi...   \n",
       "57038  @nl-nl  [ned, herv, kerk, bouwwerk, bestaande, veelhoe...   \n",
       "57039  @nl-nl  [korenmolen, koutermolen, ronde, stenen, boven...   \n",
       "57040  @nl-nl  [woonhuis, gele, baksteen, rode, bakstenen, la...   \n",
       "57041  @nl-nl  [kerk, bonifacius, eenbeukige, neogotische, kr...   \n",
       "\n",
       "                                                  vector  topics  \n",
       "0      [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1...     [3]  \n",
       "1                                       [(1, 1), (6, 1)]     [3]  \n",
       "2                                       [(1, 1), (6, 1)]     [3]  \n",
       "3                                       [(1, 1), (6, 1)]     [3]  \n",
       "4                                       [(1, 1), (6, 1)]     [3]  \n",
       "...                                                  ...     ...  \n",
       "57037  [(68, 1), (141, 1), (175, 2), (192, 1), (236, ...     [8]  \n",
       "57038  [(24, 1), (54, 2), (85, 1), (175, 1), (221, 1)...  [1, 5]  \n",
       "57039  [(73, 1), (165, 1), (234, 1), (506, 1), (768, ...  [0, 9]  \n",
       "57040  [(5, 1), (42, 2), (175, 1), (192, 1), (236, 1)...     [8]  \n",
       "57041  [(15, 1), (42, 1), (54, 1), (85, 1), (175, 1),...     [1]  \n",
       "\n",
       "[57042 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_topics):\n",
    "    dfs[39][f'topic_{i}'] = dfs[39]['topics'].apply(lambda t: True if i in t else False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sub = dfs[39][dfs[39]['topic_7']==True]\n",
    "sub_df = torch.zeros(len(sub),3)\n",
    "sub_df[:,0] = sub.s.tolist()\n",
    "sub_df[:,1] = data.r2i['key']\n",
    "sub_df[:,2] = data.e2i['key']\n",
    "#sub_df = torch.tensor([sub.s.tolist(),len(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[272144,\n",
       " 272146,\n",
       " 272148,\n",
       " 272150,\n",
       " 272152,\n",
       " 272154,\n",
       " 272156,\n",
       " 272158,\n",
       " 272160,\n",
       " 272184,\n",
       " 272212,\n",
       " 272218,\n",
       " 272236,\n",
       " 272238,\n",
       " 272240,\n",
       " 272254,\n",
       " 272266,\n",
       " 272268,\n",
       " 272270,\n",
       " 272274,\n",
       " 272312,\n",
       " 272314,\n",
       " 272316,\n",
       " 272318,\n",
       " 272322,\n",
       " 272366,\n",
       " 272370,\n",
       " 272372,\n",
       " 272374,\n",
       " 272442,\n",
       " 272490,\n",
       " 272492,\n",
       " 272494,\n",
       " 272496,\n",
       " 272498,\n",
       " 272500,\n",
       " 272502,\n",
       " 272504,\n",
       " 272506,\n",
       " 272508,\n",
       " 272510,\n",
       " 272512,\n",
       " 272540,\n",
       " 272552,\n",
       " 272570,\n",
       " 272580,\n",
       " 272582,\n",
       " 272608,\n",
       " 272610,\n",
       " 272612,\n",
       " 272614,\n",
       " 272672,\n",
       " 272696,\n",
       " 272718,\n",
       " 272754,\n",
       " 272756,\n",
       " 272758,\n",
       " 272864,\n",
       " 272866,\n",
       " 272868,\n",
       " 272892,\n",
       " 272898,\n",
       " 272906,\n",
       " 272916,\n",
       " 272950,\n",
       " 272974,\n",
       " 273010,\n",
       " 273012,\n",
       " 273014,\n",
       " 273042,\n",
       " 273044,\n",
       " 273046,\n",
       " 273100,\n",
       " 273114,\n",
       " 273168,\n",
       " 273170,\n",
       " 273172,\n",
       " 273174,\n",
       " 273176,\n",
       " 273178,\n",
       " 273180,\n",
       " 273182,\n",
       " 273184,\n",
       " 273186,\n",
       " 273298,\n",
       " 273300,\n",
       " 273302,\n",
       " 273304,\n",
       " 273376,\n",
       " 273378,\n",
       " 273380,\n",
       " 273398,\n",
       " 273402,\n",
       " 273404,\n",
       " 273406,\n",
       " 273408,\n",
       " 273410,\n",
       " 273412,\n",
       " 273414,\n",
       " 273416,\n",
       " 273418,\n",
       " 273420,\n",
       " 273422,\n",
       " 273424,\n",
       " 273458,\n",
       " 273468,\n",
       " 273470,\n",
       " 273472,\n",
       " 273492,\n",
       " 273498,\n",
       " 273518,\n",
       " 273530,\n",
       " 273548,\n",
       " 273550,\n",
       " 273552,\n",
       " 273554,\n",
       " 273556,\n",
       " 273558,\n",
       " 273566,\n",
       " 273568,\n",
       " 273570,\n",
       " 273572,\n",
       " 273578,\n",
       " 273662,\n",
       " 273672,\n",
       " 273678,\n",
       " 273716,\n",
       " 273720,\n",
       " 273722,\n",
       " 273750,\n",
       " 273758,\n",
       " 273760,\n",
       " 273762,\n",
       " 273764,\n",
       " 273766,\n",
       " 273768,\n",
       " 273854,\n",
       " 273978,\n",
       " 274038,\n",
       " 274040,\n",
       " 274068,\n",
       " 274076,\n",
       " 274100,\n",
       " 274236,\n",
       " 274238,\n",
       " 274240,\n",
       " 274258,\n",
       " 274278,\n",
       " 274290,\n",
       " 274292,\n",
       " 274404,\n",
       " 274408,\n",
       " 274414,\n",
       " 274426,\n",
       " 274432,\n",
       " 274448,\n",
       " 274452,\n",
       " 274456,\n",
       " 274460,\n",
       " 274464,\n",
       " 274470,\n",
       " 274474,\n",
       " 274478,\n",
       " 274480,\n",
       " 274510,\n",
       " 274518,\n",
       " 274520,\n",
       " 274522,\n",
       " 274524,\n",
       " 274528,\n",
       " 274530,\n",
       " 274534,\n",
       " 274548,\n",
       " 274550,\n",
       " 274574,\n",
       " 274576,\n",
       " 274582,\n",
       " 274604,\n",
       " 274628,\n",
       " 274632,\n",
       " 274634,\n",
       " 274638,\n",
       " 274688,\n",
       " 274752,\n",
       " 274822,\n",
       " 274858,\n",
       " 274864,\n",
       " 274866,\n",
       " 274876,\n",
       " 274890,\n",
       " 274892,\n",
       " 274894,\n",
       " 274978,\n",
       " 274980,\n",
       " 275052,\n",
       " 275056,\n",
       " 275096,\n",
       " 275120,\n",
       " 275122,\n",
       " 275160,\n",
       " 275308,\n",
       " 275322,\n",
       " 275324,\n",
       " 275342,\n",
       " 275344,\n",
       " 275356,\n",
       " 275360,\n",
       " 275362,\n",
       " 275364,\n",
       " 275366,\n",
       " 275422,\n",
       " 275426,\n",
       " 275428,\n",
       " 275438,\n",
       " 275440,\n",
       " 275468,\n",
       " 275474,\n",
       " 275480,\n",
       " 275482,\n",
       " 275486,\n",
       " 275490,\n",
       " 275514,\n",
       " 275568,\n",
       " 275632,\n",
       " 275634,\n",
       " 275710,\n",
       " 275714,\n",
       " 275720,\n",
       " 275726,\n",
       " 275728,\n",
       " 275730,\n",
       " 275732,\n",
       " 275734,\n",
       " 275736,\n",
       " 275738,\n",
       " 275742,\n",
       " 275744,\n",
       " 275746,\n",
       " 275748,\n",
       " 275820,\n",
       " 275826,\n",
       " 275888,\n",
       " 275892,\n",
       " 275894,\n",
       " 275932,\n",
       " 275946,\n",
       " 275952,\n",
       " 275954,\n",
       " 275964,\n",
       " 275974,\n",
       " 275976,\n",
       " 275978,\n",
       " 275980,\n",
       " 275982,\n",
       " 275984,\n",
       " 276288,\n",
       " 276466,\n",
       " 276468,\n",
       " 276520,\n",
       " 276522,\n",
       " 276524,\n",
       " 276526,\n",
       " 276528,\n",
       " 276530,\n",
       " 276532,\n",
       " 276534,\n",
       " 276536,\n",
       " 276538,\n",
       " 276540,\n",
       " 276542,\n",
       " 276544,\n",
       " 276546,\n",
       " 276548,\n",
       " 276550,\n",
       " 276552,\n",
       " 276582,\n",
       " 276584,\n",
       " 276586,\n",
       " 276708,\n",
       " 276712,\n",
       " 276738,\n",
       " 276756,\n",
       " 276790,\n",
       " 276946,\n",
       " 276964,\n",
       " 276968,\n",
       " 276970,\n",
       " 276986,\n",
       " 276990,\n",
       " 276992,\n",
       " 276994,\n",
       " 276996,\n",
       " 276998,\n",
       " 277000,\n",
       " 277002,\n",
       " 277004,\n",
       " 277006,\n",
       " 277008,\n",
       " 277010,\n",
       " 277012,\n",
       " 277014,\n",
       " 277016,\n",
       " 277018,\n",
       " 277020,\n",
       " 277022,\n",
       " 277024,\n",
       " 277026,\n",
       " 277028,\n",
       " 277030,\n",
       " 277032,\n",
       " 277034,\n",
       " 277036,\n",
       " 277038,\n",
       " 277040,\n",
       " 277042,\n",
       " 277044,\n",
       " 277046,\n",
       " 277048,\n",
       " 277050,\n",
       " 277052,\n",
       " 277054,\n",
       " 277056,\n",
       " 277058,\n",
       " 277060,\n",
       " 277062,\n",
       " 277064,\n",
       " 277066,\n",
       " 277068,\n",
       " 277070,\n",
       " 277072,\n",
       " 277074,\n",
       " 277076,\n",
       " 277078,\n",
       " 277080,\n",
       " 277082,\n",
       " 277084,\n",
       " 277086,\n",
       " 277088,\n",
       " 277090,\n",
       " 277098,\n",
       " 277100,\n",
       " 277102,\n",
       " 277104,\n",
       " 277106,\n",
       " 277108,\n",
       " 277110,\n",
       " 277112,\n",
       " 277114,\n",
       " 277116,\n",
       " 277118,\n",
       " 277120,\n",
       " 277136,\n",
       " 277138,\n",
       " 277140,\n",
       " 277142,\n",
       " 277144,\n",
       " 277146,\n",
       " 277148,\n",
       " 277150,\n",
       " 277178,\n",
       " 277180,\n",
       " 277182,\n",
       " 277812,\n",
       " 277948,\n",
       " 277952,\n",
       " 277970,\n",
       " 278102,\n",
       " 278104,\n",
       " 278106,\n",
       " 278648,\n",
       " 278668,\n",
       " 278684,\n",
       " 278720,\n",
       " 278722,\n",
       " 278724,\n",
       " 278744,\n",
       " 278764,\n",
       " 278808,\n",
       " 278886,\n",
       " 278898,\n",
       " 278900,\n",
       " 278958,\n",
       " 278972,\n",
       " 278974,\n",
       " 278976,\n",
       " 278978,\n",
       " 278980,\n",
       " 278984,\n",
       " 278986,\n",
       " 278988,\n",
       " 278990,\n",
       " 278992,\n",
       " 278994,\n",
       " 278996,\n",
       " 278998,\n",
       " 279000,\n",
       " 279002,\n",
       " 279004,\n",
       " 279006,\n",
       " 279008,\n",
       " 279010,\n",
       " 279012,\n",
       " 279014,\n",
       " 279016,\n",
       " 279018,\n",
       " 279020,\n",
       " 279036,\n",
       " 279066,\n",
       " 279070,\n",
       " 279072,\n",
       " 279126,\n",
       " 279128,\n",
       " 279130,\n",
       " 279132,\n",
       " 279136,\n",
       " 279266,\n",
       " 279282,\n",
       " 279294,\n",
       " 279296,\n",
       " 279402,\n",
       " 279410,\n",
       " 279412,\n",
       " 279414,\n",
       " 279426,\n",
       " 279432,\n",
       " 279434,\n",
       " 279436,\n",
       " 279438,\n",
       " 279462,\n",
       " 279532,\n",
       " 279624,\n",
       " 279650,\n",
       " 279652,\n",
       " 279654,\n",
       " 279656,\n",
       " 279744,\n",
       " 279858,\n",
       " 279888,\n",
       " 279920,\n",
       " 279922,\n",
       " 279926,\n",
       " 279990,\n",
       " 280030,\n",
       " 280050,\n",
       " 280062,\n",
       " 280064,\n",
       " 280066,\n",
       " 280068,\n",
       " 280072,\n",
       " 280208,\n",
       " 280210,\n",
       " 280212,\n",
       " 280252,\n",
       " 280316,\n",
       " 280318,\n",
       " 280342,\n",
       " 280436,\n",
       " 280482,\n",
       " 280486,\n",
       " 280488,\n",
       " 280490,\n",
       " 280492,\n",
       " 280494,\n",
       " 280516,\n",
       " 280534,\n",
       " 280536,\n",
       " 280538,\n",
       " 280540,\n",
       " 280542,\n",
       " 280544,\n",
       " 280546,\n",
       " 280634,\n",
       " 280636,\n",
       " 280638,\n",
       " 280688,\n",
       " 280690,\n",
       " 280708,\n",
       " 280714,\n",
       " 280718,\n",
       " 280750,\n",
       " 280752,\n",
       " 280838,\n",
       " 280890,\n",
       " 280892,\n",
       " 280896,\n",
       " 280900,\n",
       " 280902,\n",
       " 280906,\n",
       " 280908,\n",
       " 280910,\n",
       " 280914,\n",
       " 280916,\n",
       " 280918,\n",
       " 280922,\n",
       " 280924,\n",
       " 280926,\n",
       " 280928,\n",
       " 280930,\n",
       " 280932,\n",
       " 280934,\n",
       " 280938,\n",
       " 280940,\n",
       " 281046,\n",
       " 281048,\n",
       " 281074,\n",
       " 281082,\n",
       " 281084,\n",
       " 281086,\n",
       " 281088,\n",
       " 281090,\n",
       " 281092,\n",
       " 281094,\n",
       " 281096,\n",
       " 281206,\n",
       " 281218,\n",
       " 281266,\n",
       " 281290,\n",
       " 281342,\n",
       " 281384,\n",
       " 281478,\n",
       " 281482,\n",
       " 281522,\n",
       " 281540,\n",
       " 281590,\n",
       " 281602,\n",
       " 281610,\n",
       " 281638,\n",
       " 281640,\n",
       " 281714,\n",
       " 281716,\n",
       " 281720,\n",
       " 281738,\n",
       " 281846,\n",
       " 282064,\n",
       " 282276,\n",
       " 282278,\n",
       " 282280,\n",
       " 282316,\n",
       " 282332,\n",
       " 282336,\n",
       " 282338,\n",
       " 282340,\n",
       " 282342,\n",
       " 282344,\n",
       " 282346,\n",
       " 282348,\n",
       " 282350,\n",
       " 282352,\n",
       " 282354,\n",
       " 282356,\n",
       " 282358,\n",
       " 282360,\n",
       " 282362,\n",
       " 282364,\n",
       " 282366,\n",
       " 282368,\n",
       " 282370,\n",
       " 282372,\n",
       " 282374,\n",
       " 282376,\n",
       " 282378,\n",
       " 282380,\n",
       " 282382,\n",
       " 282384,\n",
       " 282386,\n",
       " 282388,\n",
       " 282390,\n",
       " 282392,\n",
       " 282394,\n",
       " 282396,\n",
       " 282398,\n",
       " 282400,\n",
       " 282402,\n",
       " 282404,\n",
       " 282406,\n",
       " 282408,\n",
       " 282410,\n",
       " 282412,\n",
       " 282414,\n",
       " 282416,\n",
       " 282418,\n",
       " 282420,\n",
       " 282422,\n",
       " 282424,\n",
       " 282438,\n",
       " 282480,\n",
       " 282574,\n",
       " 282682,\n",
       " 282744,\n",
       " 282746,\n",
       " 282788,\n",
       " 282796,\n",
       " 282798,\n",
       " 282836,\n",
       " 282838,\n",
       " 282842,\n",
       " 282854,\n",
       " 282890,\n",
       " 282922,\n",
       " 282972,\n",
       " 282974,\n",
       " 282976,\n",
       " 282978,\n",
       " 283162,\n",
       " 283272,\n",
       " 283278,\n",
       " 283290,\n",
       " 283294,\n",
       " 283376,\n",
       " 283398,\n",
       " 283402,\n",
       " 283406,\n",
       " 283408,\n",
       " 283410,\n",
       " 283412,\n",
       " 283414,\n",
       " 283416,\n",
       " 283418,\n",
       " 283432,\n",
       " 283434,\n",
       " 283468,\n",
       " 283470,\n",
       " 283472,\n",
       " 283474,\n",
       " 283476,\n",
       " 283478,\n",
       " 283480,\n",
       " 283482,\n",
       " 283484,\n",
       " 283486,\n",
       " 283488,\n",
       " 283494,\n",
       " 283500,\n",
       " 283502,\n",
       " 283504,\n",
       " 283506,\n",
       " 283508,\n",
       " 283510,\n",
       " 283512,\n",
       " 283514,\n",
       " 283516,\n",
       " 283520,\n",
       " 283522,\n",
       " 283532,\n",
       " 283534,\n",
       " 283536,\n",
       " 283538,\n",
       " 283540,\n",
       " 283542,\n",
       " 283544,\n",
       " 283642,\n",
       " 283646,\n",
       " 283696,\n",
       " 283716,\n",
       " 283718,\n",
       " 283720,\n",
       " 283786,\n",
       " 283788,\n",
       " 283792,\n",
       " 283794,\n",
       " 283798,\n",
       " 283812,\n",
       " 283826,\n",
       " 283828,\n",
       " 283836,\n",
       " 283980,\n",
       " 284010,\n",
       " 284274,\n",
       " 284288,\n",
       " 284320,\n",
       " 284322,\n",
       " 284416,\n",
       " 284420,\n",
       " 284434,\n",
       " 284436,\n",
       " 284472,\n",
       " 284474,\n",
       " 284476,\n",
       " 284478,\n",
       " 284480,\n",
       " 284482,\n",
       " 284502,\n",
       " 284574,\n",
       " 284580,\n",
       " 284582,\n",
       " 284586,\n",
       " 284602,\n",
       " 284604,\n",
       " 284606,\n",
       " 284608,\n",
       " 284610,\n",
       " 284632,\n",
       " 284668,\n",
       " 284674,\n",
       " 284678,\n",
       " 284690,\n",
       " 284702,\n",
       " 284708,\n",
       " 284728,\n",
       " 284768,\n",
       " 284864,\n",
       " 284866,\n",
       " 284884,\n",
       " 284890,\n",
       " 284892,\n",
       " 284898,\n",
       " 284904,\n",
       " 284930,\n",
       " 284936,\n",
       " 284940,\n",
       " 284946,\n",
       " 284962,\n",
       " 284972,\n",
       " 284996,\n",
       " 285002,\n",
       " 285016,\n",
       " 285098,\n",
       " 285104,\n",
       " 285116,\n",
       " 285160,\n",
       " 285162,\n",
       " 285164,\n",
       " 285172,\n",
       " 285190,\n",
       " 285206,\n",
       " 285230,\n",
       " 285232,\n",
       " 285236,\n",
       " 285252,\n",
       " 285302,\n",
       " 285304,\n",
       " 285344,\n",
       " 285356,\n",
       " 285360,\n",
       " 285376,\n",
       " 285388,\n",
       " 285430,\n",
       " 285434,\n",
       " 285446,\n",
       " 285468,\n",
       " 285472,\n",
       " 285482,\n",
       " 285490,\n",
       " 285492,\n",
       " 285494,\n",
       " 285502,\n",
       " 285514,\n",
       " 285552,\n",
       " 285578,\n",
       " 285612,\n",
       " 285638,\n",
       " 285644,\n",
       " 285646,\n",
       " 285666,\n",
       " 285676,\n",
       " 285700,\n",
       " 285702,\n",
       " 285706,\n",
       " 285708,\n",
       " 285712,\n",
       " 285722,\n",
       " 285726,\n",
       " 285780,\n",
       " 285788,\n",
       " 285792,\n",
       " 285800,\n",
       " 285894,\n",
       " 285896,\n",
       " 285906,\n",
       " 285908,\n",
       " 285918,\n",
       " 285924,\n",
       " 285956,\n",
       " 286036,\n",
       " 286162,\n",
       " 286190,\n",
       " 286194,\n",
       " 286202,\n",
       " 286224,\n",
       " 286226,\n",
       " 286228,\n",
       " 286230,\n",
       " 286232,\n",
       " 286234,\n",
       " 286236,\n",
       " 286238,\n",
       " 286240,\n",
       " 286242,\n",
       " 286244,\n",
       " 286246,\n",
       " 286248,\n",
       " 286250,\n",
       " 286284,\n",
       " 286314,\n",
       " 286356,\n",
       " 286360,\n",
       " 286370,\n",
       " 286374,\n",
       " 286386,\n",
       " 286388,\n",
       " 286404,\n",
       " 286478,\n",
       " 286482,\n",
       " 286534,\n",
       " 286578,\n",
       " 286580,\n",
       " 286636,\n",
       " 286690,\n",
       " 286698,\n",
       " 286752,\n",
       " 286758,\n",
       " 286768,\n",
       " 286778,\n",
       " 286782,\n",
       " 286784,\n",
       " 286790,\n",
       " 286792,\n",
       " 286808,\n",
       " 286844,\n",
       " 286856,\n",
       " 286884,\n",
       " 286886,\n",
       " 286888,\n",
       " 286898,\n",
       " 286912,\n",
       " 286938,\n",
       " 286944,\n",
       " 286946,\n",
       " 286968,\n",
       " 287150,\n",
       " 287154,\n",
       " 287156,\n",
       " 287178,\n",
       " 287180,\n",
       " 287182,\n",
       " 287236,\n",
       " 287238,\n",
       " 287240,\n",
       " 287256,\n",
       " 287272,\n",
       " 287274,\n",
       " 287276,\n",
       " 287292,\n",
       " 287294,\n",
       " 287308,\n",
       " 287318,\n",
       " 287320,\n",
       " 287322,\n",
       " 287324,\n",
       " 287326,\n",
       " 287328,\n",
       " 287376,\n",
       " 287504,\n",
       " 287524,\n",
       " 287526,\n",
       " 287528,\n",
       " 287534,\n",
       " 287536,\n",
       " 287538,\n",
       " 287540,\n",
       " 287542,\n",
       " 287544,\n",
       " 287548,\n",
       " 287550,\n",
       " 287552,\n",
       " 287554,\n",
       " 287620,\n",
       " 287674,\n",
       " 287676,\n",
       " 287678,\n",
       " 288018,\n",
       " 288024,\n",
       " 288026,\n",
       " 288028,\n",
       " 288042,\n",
       " 288124,\n",
       " 288126,\n",
       " 288174,\n",
       " 288212,\n",
       " 288240,\n",
       " 288278,\n",
       " 288280,\n",
       " 288288,\n",
       " 288310,\n",
       " 288350,\n",
       " 288352,\n",
       " 288358,\n",
       " 288406,\n",
       " 288476,\n",
       " 288478,\n",
       " 288526,\n",
       " 288546,\n",
       " 288584,\n",
       " 288674,\n",
       " 288756,\n",
       " 288758,\n",
       " 288772,\n",
       " 288780,\n",
       " 288872]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[39][dfs[39]['topic_7']==True].s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>vector</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [s, p, o, text, type, text_preprocessed, vector, topics]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[39][dfs[39]['topics'].isin([7])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boerderij', 'vrijstaand', 'woonhuis']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(word_array, stopword_list):\n",
    "    return [word for word in word_array\n",
    "             if word not in stopword_list]\n",
    "remove_stopwords(['boerderij', 'vrijstaand', 'woonhuis', 'onder'], get_stopword_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [exterieur, overzicht, voorgevel, kleine, gebo...\n",
       "1                                   [exterieur, overzicht]\n",
       "2                                   [exterieur, overzicht]\n",
       "3                                   [exterieur, overzicht]\n",
       "4                                   [exterieur, overzicht]\n",
       "                               ...                        \n",
       "57037    [boerderij, vrijstaand, woonhuis, pannen, schi...\n",
       "57038    [ned, herv, kerk, bouwwerk, bestaande, veelhoe...\n",
       "57039    [korenmolen, koutermolen, ronde, stenen, boven...\n",
       "57040    [woonhuis, gele, baksteen, rode, bakstenen, la...\n",
       "57041    [kerk, bonifacius, eenbeukige, neogotische, kr...\n",
       "Name: text_preprocessed, Length: 57042, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [exterieur, overzicht, voorgevel, kleine, gebo...\n",
       "1                                   [exterieur, overzicht]\n",
       "2                                   [exterieur, overzicht]\n",
       "3                                   [exterieur, overzicht]\n",
       "4                                   [exterieur, overzicht]\n",
       "                               ...                        \n",
       "57037    [boerderij, vrijstaand, woonhuis, onder, panne...\n",
       "57038    [ned, herv, kerk, bouwwerk, bestaande, uit, he...\n",
       "57039    [korenmolen, de, koutermolen, ronde, stenen, b...\n",
       "57040    [woonhuis, in, gele, baksteen, met, rode, baks...\n",
       "57041    [kerk, van, de, bonifacius, eenbeukige, neogot...\n",
       "Name: text, Length: 57042, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda t: gensim.utils.simple_preprocess(t, deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (750369112.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    df['text_processed'] = df['text'].map(lambda x: '' if re.sub('[\\:,\\.!?]', '', x))\u001b[0m\n\u001b[1;37m                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "for r in rr:\n",
    "    df = pd.DataFrame(data.triples[data.triples[:,1]== r], columns=['s','p','o'])\n",
    "    df['text'] = df['o'].apply(lambda t: data.i2e[t][0])\n",
    "    df['type'] = df['o'].apply(lambda t: data.i2e[t][1])\n",
    "    df['text'] = df['text'].apply(lambda t:'' if re.match('(POLYGON)',t) else t)\n",
    "    mean_num_words = df['text'].str.count(r'([A-Za-z\\:\\.\\/]{3,})').mean()\n",
    "    #print(mean_num_words)\n",
    "    if mean_num_words > 3:\n",
    "\n",
    "\n",
    "        \n",
    "        df['text_processed'] = df['text'].map(lambda x: '' if re.sub('[\\:,\\.!?]', '', x))\n",
    "        df['text_processed'] = df['text_processed'].map(lambda x: x.lower())\n",
    "        # for word in dutch_stopwords:\n",
    "        #     df['text_processed'] = df['text_processed'].map(lambda x: re.sub(rf'[][{word}][]', '', x)) \n",
    "        # df['text_processed'] = df['text_processed']\n",
    "\n",
    "        dfs[r] = df\n",
    "\n",
    "        # Join the different processed titles together.\n",
    "        long_string = ' '.join(list(df['text_processed'].values))\n",
    "\n",
    "        #for word in dutch_stopwords:\n",
    "        #    long_string= long_string.replace(f'{word} ','')\n",
    "        #long_string= long_string.replace(f'newline ','')\n",
    "\n",
    "        # Create a WordCloud object\n",
    "        wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "        # Generate a word cloud\n",
    "        wordcloud.generate(long_string)\n",
    "\n",
    "        # Visualize the word cloud\n",
    "        wordcloud.to_image().show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Noctris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exterieur', 'overzicht', 'voorgevel', 'kleine', 'gebouw', 'links', 'midden', 'wachtkamer', 'apotheek']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(0, '0.042*\"zijgevel\" + 0.018*\"overzicht\" + 0.015*\"voorgevel\" + 0.010*\"rechter\" + 0.008*\"vensters\" + 0.006*\"twee\" + 0.005*\"boven\" + 0.005*\"deel\" + 0.005*\"achtergevel\" + 0.004*\"exterieur\"'), (1, '0.045*\"voorgevel\" + 0.018*\"nr\" + 0.013*\"achtergevel\" + 0.013*\"zijgevel\" + 0.006*\"overzicht\" + 0.005*\"houten\" + 0.005*\"vensters\" + 0.005*\"kerk\" + 0.004*\"voorzien\" + 0.004*\"twee\"'), (2, '0.014*\"achtergevel\" + 0.011*\"nr\" + 0.011*\"achtkante\" + 0.010*\"voorgevel\" + 0.010*\"overzicht\" + 0.009*\"gefotografeerd\" + 0.008*\"aanzicht\" + 0.007*\"twee\" + 0.007*\"gevel\" + 0.006*\"exterieur\"'), (3, '0.024*\"exterieur\" + 0.011*\"twee\" + 0.008*\"zijgevel\" + 0.006*\"achtkante\" + 0.006*\"vensters\" + 0.006*\"gevel\" + 0.005*\"achtergevel\" + 0.004*\"belang\" + 0.004*\"houten\" + 0.004*\"vanwege\"'), (4, '0.063*\"voorgevel\" + 0.030*\"overzicht\" + 0.022*\"exterieur\" + 0.017*\"boerderij\" + 0.015*\"zijgevel\" + 0.008*\"linker\" + 0.008*\"achtergevel\" + 0.007*\"vensters\" + 0.006*\"achtkante\" + 0.006*\"houten\"'), (5, '0.027*\"overzicht\" + 0.025*\"zijgevel\" + 0.017*\"achtkante\" + 0.012*\"gefotografeerd\" + 0.011*\"stellingmolen\" + 0.010*\"linker\" + 0.009*\"kerk\" + 0.006*\"vanaf\" + 0.006*\"complex\" + 0.005*\"huis\"'), (6, '0.011*\"voorgevel\" + 0.009*\"overzicht\" + 0.008*\"twee\" + 0.006*\"kerk\" + 0.006*\"vanwege\" + 0.006*\"detail\" + 0.005*\"achtkante\" + 0.005*\"complex\" + 0.005*\"eeuw\" + 0.005*\"vensters\"'), (7, '0.017*\"overzicht\" + 0.013*\"zijgevel\" + 0.010*\"twee\" + 0.007*\"houten\" + 0.007*\"rechter\" + 0.005*\"voorzien\" + 0.005*\"gevel\" + 0.005*\"exterieur\" + 0.005*\"boven\" + 0.005*\"vensters\"'), (8, '0.038*\"overzicht\" + 0.011*\"voorgevel\" + 0.008*\"achterzijde\" + 0.007*\"zijgevel\" + 0.006*\"exterieur\" + 0.006*\"vanaf\" + 0.005*\"huis\" + 0.005*\"aanzicht\" + 0.005*\"gezien\" + 0.005*\"boerderij\"'), (9, '0.041*\"overzicht\" + 0.029*\"exterieur\" + 0.015*\"gevel\" + 0.012*\"voorgevel\" + 0.008*\"eeuw\" + 0.007*\"boerderij\" + 0.005*\"zuidgevel\" + 0.005*\"twee\" + 0.005*\"toren\" + 0.004*\"voorzijde\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noctris\\.virtualenvs\\rdf-literal-preprocessing-20b3_M0v\\lib\\site-packages\\pyLDAvis\\_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "\n",
    "stop_words = stopwords.words('dutch')\n",
    "stop_words.extend(['newline'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "models = {}\n",
    "for r,df in dfs.items():\n",
    "    text_data = df.text_processed.values.tolist()\n",
    "    data_words = list(sent_to_words(text_data))\n",
    "\n",
    "    # remove stop words\n",
    "    data_words = remove_stopwords(data_words)\n",
    "\n",
    "    print(data_words[:1][0][:30])\n",
    "\n",
    "\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_words\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    # View\n",
    "    print(corpus[:1][0][:30])\n",
    "    # number of topics\n",
    "    num_topics = 10\n",
    "\n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "\n",
    "    # Print the Keyword in the 10 topics\n",
    "    print(lda_model.print_topics())\n",
    "    doc_lda = lda_model[corpus]\n",
    "    models[r] = (lda_model,corpus)\n",
    "\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    # # Visualize the topics\n",
    "    # pyLDAvis.enable_notebook()\n",
    "\n",
    "    # LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "\n",
    "    # # # this is a bit time consuming - make the if statement True\n",
    "    # # # if you want to execute visualization prep yourself\n",
    "    # if 1 == 1:\n",
    "    #     LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    #     with open(LDAvis_data_filepath, 'wb') as f:\n",
    "    #         pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "    # # load the pre-prepared pyLDAvis data from disk\n",
    "    # with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    #     LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "    # pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "\n",
    "    # LDAvis_prepared\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dfs[9]['text_processed'].iloc[23]\n",
    "id2word.doc2bow(remove_stopwords(list(sent_to_words([t])))[0])\n",
    "[x[0] for x in sorted(lda_model.get_document_topics(id2word.doc2bow(remove_stopwords(list(sent_to_words([t])))[0])), key=lambda x: x[1], reverse=True)[:3] if x[1]>0.1]\n",
    "\n",
    "# remove_stopwords(t)\n",
    "#     data_words = list(sent_to_words(text_data))\n",
    "\n",
    "#     # remove stop words\n",
    "#     data_words = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exterieur overzicht administratiegebouw voorgevel binnengasthuisstraat 9  kleine gebouw links/midden is wachtkamer/apotheek'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[9]['text_processed'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43015"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('overzicht', 0.040573794),\n",
       " ('exterieur', 0.028770167),\n",
       " ('gevel', 0.015426227),\n",
       " ('voorgevel', 0.01178268),\n",
       " ('eeuw', 0.008472809),\n",
       " ('boerderij', 0.006760539),\n",
       " ('zuidgevel', 0.005024846),\n",
       " ('twee', 0.0049154814),\n",
       " ('toren', 0.0045687947),\n",
       " ('voorzijde', 0.0043822383)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.show_topic(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.042350933, 'zijgevel'),\n",
       "  (0.017903773, 'overzicht'),\n",
       "  (0.014605292, 'voorgevel'),\n",
       "  (0.010351551, 'rechter'),\n",
       "  (0.007596633, 'vensters'),\n",
       "  (0.006375451, 'twee'),\n",
       "  (0.005431587, 'boven'),\n",
       "  (0.005430931, 'deel'),\n",
       "  (0.0054016714, 'achtergevel'),\n",
       "  (0.004311797, 'exterieur'),\n",
       "  (0.0039438996, 'houten'),\n",
       "  (0.003926319, 'huis'),\n",
       "  (0.0038003884, 'verdieping'),\n",
       "  (0.0035305512, 'linker'),\n",
       "  (0.0034399512, 'noordgevel'),\n",
       "  (0.0034246587, 'deur'),\n",
       "  (0.003343821, 'woongedeelte'),\n",
       "  (0.0032433395, 'drie'),\n",
       "  (0.0029321224, 'xviii'),\n",
       "  (0.0029315404, 'vanwege')],\n",
       " -2.614338742936087)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.top_topics(corpus)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0079872204472844\n",
      "0.0\n",
      "1.1012987012987012\n",
      "2.0\n",
      "0.9636363636363636\n",
      "0.0\n",
      "1.2016129032258065\n",
      "0.0\n",
      "6.784874253663831e-05\n",
      "2.2054044468089824\n",
      "23.614512113881\n",
      "2.005254938375823\n",
      "2.205349831680466\n",
      "2.6569912519718915\n",
      "2.242540904716073\n",
      "2.0\n",
      "1.8888888888888888\n",
      "3.5714285714285716\n",
      "2.0\n",
      "1.1748451643639828\n",
      "0.0\n",
      "2.4165078608861363\n",
      "0.0\n",
      "0.00023820867079561695\n",
      "1.5560371517027864\n",
      "0.009433962264150943\n",
      "0.005482456140350877\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.641025641025641\n",
      "1.0103761348897535\n",
      "1.8713826366559485\n",
      "1.1085271317829457\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "        # Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "for r in rr:\n",
    "    df = pd.DataFrame(data.triples[data.triples[:,1]== r], columns=['s','p','o'])\n",
    "    df['text'] = df['o'].apply(lambda t: data.i2e[t][0])\n",
    "    df['type'] = df['o'].apply(lambda t: data.i2e[t][1])\n",
    "    mean_num_words = df['text'].str.count(r'([A-Za-z\\:\\.\\/]{3,})').mean()\n",
    "    print(mean_num_words)\n",
    "    #if mean_num_words > 3:\n",
    "    #print(\"hi\")\n",
    "\n",
    "        #df['text_processed'] = df['text'].map(lambda x: re.sub('[\\:,\\.!?]', '', x))\n",
    "        #df['text_processed'] = df['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "\n",
    "        # # Join the different processed titles together.\n",
    "        # long_string = ','.join(list(df['paper_text_processed'].values))\n",
    "\n",
    "        # # Create a WordCloud object\n",
    "        # wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "        # # Generate a word cloud\n",
    "        # wordcloud.generate(long_string)\n",
    "\n",
    "        # # Visualize the word cloud\n",
    "        # wordcloud.to_image()\n",
    "\n",
    "## Print out the first rows of papers\n",
    "#papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.DataFrame(data.triples[data.triples[:,1]== 53], columns=['s','p','o'])\n",
    "    df['text'] = df['o'].apply(lambda t: data.i2e[t][0])\n",
    "#df['text'] = df['text'].astype('str') \n",
    "    df['type'] = df['o'].apply(lambda t: data.i2e[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271513</td>\n",
       "      <td>53</td>\n",
       "      <td>25961</td>\n",
       "      <td>Dusselsma, N.W.</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271514</td>\n",
       "      <td>53</td>\n",
       "      <td>23730</td>\n",
       "      <td>Cuypers, Pierre Joseph Hubert</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271515</td>\n",
       "      <td>53</td>\n",
       "      <td>23730</td>\n",
       "      <td>Cuypers, Pierre Joseph Hubert</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271522</td>\n",
       "      <td>53</td>\n",
       "      <td>23730</td>\n",
       "      <td>Cuypers, Pierre Joseph Hubert</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271523</td>\n",
       "      <td>53</td>\n",
       "      <td>23730</td>\n",
       "      <td>Cuypers, Pierre Joseph Hubert</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>271524</td>\n",
       "      <td>53</td>\n",
       "      <td>74522</td>\n",
       "      <td>Sandt, Anton van der</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>271535</td>\n",
       "      <td>53</td>\n",
       "      <td>26360</td>\n",
       "      <td>Embden, F.C.E. van</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        s   p      o                           text  type\n",
       "0  271513  53  25961                Dusselsma, N.W.  none\n",
       "1  271514  53  23730  Cuypers, Pierre Joseph Hubert  none\n",
       "2  271515  53  23730  Cuypers, Pierre Joseph Hubert  none\n",
       "3  271522  53  23730  Cuypers, Pierre Joseph Hubert  none\n",
       "4  271523  53  23730  Cuypers, Pierre Joseph Hubert  none\n",
       "5  271524  53  74522           Sandt, Anton van der  none\n",
       "6  271535  53  26360             Embden, F.C.E. van  none"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data.triples[data.triples[:,1]== 32], columns=['s','p','o'])\n",
    "df['text'] = df['o'].apply(lambda t: data.i2e[t][0])\n",
    "#df['text'] = df['text'].astype('str') \n",
    "df['type'] = df['o'].apply(lambda t: data.i2e[t][1])\n",
    "#df['count_words'] = df['text'].str.match(r'[A-Za-z0-9]+').str.get(0).groupby(lambda x: x).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8433873376996437"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.count(r'([A-Za-z0-9]+)').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://purl.org/collections/nl/am/exhibitionTitle'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.i2r[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122694</td>\n",
       "      <td>17</td>\n",
       "      <td>53008</td>\n",
       "      <td>Rijk gekleed 1750-1914</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122727</td>\n",
       "      <td>17</td>\n",
       "      <td>66314</td>\n",
       "      <td>Zomertentoonstelling</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122766</td>\n",
       "      <td>17</td>\n",
       "      <td>35585</td>\n",
       "      <td>Goed Verkeerd. Postertentoonstelling</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122814</td>\n",
       "      <td>17</td>\n",
       "      <td>65429</td>\n",
       "      <td>Willem Roelofs (1822-1897)</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122849</td>\n",
       "      <td>17</td>\n",
       "      <td>21992</td>\n",
       "      <td>Bergen aan Zee 100 jaar</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>506593</td>\n",
       "      <td>17</td>\n",
       "      <td>37219</td>\n",
       "      <td>Het geschenk. De Hollandse Meesters van een Am...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10467</th>\n",
       "      <td>506620</td>\n",
       "      <td>17</td>\n",
       "      <td>45503</td>\n",
       "      <td>Max Liebermann en zijn Nederlandse kunstenaars...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>506664</td>\n",
       "      <td>17</td>\n",
       "      <td>35587</td>\n",
       "      <td>Goed verkeerd. Geschiedenis van homoseksuele m...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10469</th>\n",
       "      <td>506695</td>\n",
       "      <td>17</td>\n",
       "      <td>32051</td>\n",
       "      <td>Een huis vol bloemen : zomerse kleurenpracht i...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>506746</td>\n",
       "      <td>17</td>\n",
       "      <td>683</td>\n",
       "      <td>'Uitmuntend fraay geteekend'. Nederlandse teke...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10471 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            s   p  ...                                               text  type\n",
       "0      122694  17  ...                             Rijk gekleed 1750-1914  none\n",
       "1      122727  17  ...                               Zomertentoonstelling  none\n",
       "2      122766  17  ...               Goed Verkeerd. Postertentoonstelling  none\n",
       "3      122814  17  ...                         Willem Roelofs (1822-1897)  none\n",
       "4      122849  17  ...                            Bergen aan Zee 100 jaar  none\n",
       "...       ...  ..  ...                                                ...   ...\n",
       "10466  506593  17  ...  Het geschenk. De Hollandse Meesters van een Am...  none\n",
       "10467  506620  17  ...  Max Liebermann en zijn Nederlandse kunstenaars...  none\n",
       "10468  506664  17  ...  Goed verkeerd. Geschiedenis van homoseksuele m...  none\n",
       "10469  506695  17  ...  Een huis vol bloemen : zomerse kleurenpracht i...  none\n",
       "10470  506746  17  ...  'Uitmuntend fraay geteekend'. Nederlandse teke...  none\n",
       "\n",
       "[10471 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['type']=='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['o'].apply(lambda t: data.i2e[t])\n",
    "df['type'] = df['o'].apply(lambda t: data.i2e[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>127442</td>\n",
       "      <td>9</td>\n",
       "      <td>508236</td>\n",
       "      <td>(hoogte uitgeklapt, none)</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59336</th>\n",
       "      <td>270079</td>\n",
       "      <td>9</td>\n",
       "      <td>507103</td>\n",
       "      <td>(diepte uitgeklapt, none)</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            s  p       o                       text  type\n",
       "1890   127442  9  508236  (hoogte uitgeklapt, none)  none\n",
       "59336  270079  9  507103  (diepte uitgeklapt, none)  none"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['type']=='none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf-literal-preprocessing-20b3_M0v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
